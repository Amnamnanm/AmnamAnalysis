AmanAnalysis: Security Analysis Tool
AmanAnalysis is a GUI-based tool designed for static and runtime analysis of executable files and directories to identify potentially malicious behavior. It provides a user-friendly interface to collect data, analyze logs, and generate risk assessments, with an optional AI-powered summary feature.
Features
GUI Interface: A modern and intuitive user interface built with customtkinter.
Static Analysis:
Select a single file (.exe, .dll, etc.) or an entire folder for analysis.
Calculates file hashes (MD5, SHA1, SHA256).
Extracts PE (Portable Executable) metadata, including imported functions.
Dumps all readable strings from binary files.
Runtime Monitoring:
Monitors process creation snapshots at regular intervals.
Logs filesystem events in key directories (e.g., user's home, temp folders).
Requires administrator privileges for full effectiveness.
Log Analysis & Risk Assessment:
Aggregates all logs from static and runtime analysis.
Scans for suspicious keywords, URLs, IP addresses, and domains.
Calculates a risk score (Low, Medium, High) based on keyword hits and contextual triggers tailored to the specified program type (e.g., "Game", "System utility").
AI-Powered Summaries (Optional):
Integrates with GGUF-format language models (via llama-cpp-python).
Generates quick or detailed summaries of the analysis findings.
Provides customizable prompts and model parameters (temperature, max tokens).
Easy Management:
All logs are organized into a logs/ directory.
Simple controls to start/stop monitoring, run analysis, and open the log folder.
Requirements
The tool is built with Python and requires several external libraries.
Core Dependencies:
customtkinter: For the graphical user interface.
pefile: For parsing PE file headers.
psutil: For process monitoring.
watchdog: For filesystem monitoring.
Optional AI Dependency:
llama-cpp-python: For running local AI model analysis.
Installation
Clone the repository or download the source code.
Install the required Python packages:
code
Bash
pip install customtkinter pefile psutil watchdog
To enable the AI features, install llama-cpp-python:
For a basic CPU-only installation:
code
Bash
pip install llama-cpp-python
For hardware acceleration (NVIDIA GPU, etc.), please refer to the official llama-cpp-python documentation for detailed installation instructions.
Usage
Run the main script:
code
Bash
python your_script_name.py
(Optional) Add AI Models:
Create an AI/ folder in the same directory as the script.
Place your pre-trained GGUF models (e.g., mistral-7b.gguf) inside the AI/ folder.
Click "Rescan models" in the UI to make them available in the dropdown menu.
Select a Target:
Click "Pick file" to select a single executable for analysis.
Click "Pick folder" to analyze all files within a directory.
Set Program Type:
Choose the most appropriate category from the "Program type" dropdown. This helps the analysis engine apply more accurate contextual rules.
Perform Analysis:
Static Analysis: Click "Static analysis â†’ log". This will inspect the target(s) without running them and save the results to logs/static/.
Runtime Monitoring:
Click "Start monitoring" to begin logging process and filesystem activity.
Run the target executable (if applicable).
Click "Stop monitoring" when you are finished. Logs are saved to logs/runtime/.
Analyze Logs: Click "Analyze logs". This will process all collected data from the logs/ directory and generate a summary in logs/findings_summary.txt. The findings will also be displayed in the main console window.
Generate AI Summary:
After running "Analyze logs", select a model from the AI dropdown.
Click "Quick AI Summary" for a brief risk assessment.
Click "Detailed AI Analysis" for a more in-depth summary that uses contextual snippets from the logs. The results are saved to logs/ai_analysis.txt and displayed in the console.
Directory Structure
The application will create the following directories and files in its root folder:
AI/: (User-created) Place your .gguf language models here.
logs/: Main directory for all generated data.
static/: Contains logs from static file analysis.
runtime/: Contains logs from process and filesystem monitoring.
tools/: A place for logs from external tools (if any).
master_log.txt: A timestamped log of all actions performed within the application.
findings_summary.txt: The detailed report generated by the "Analyze logs" action.
ai_analysis.txt: The output from the AI summary generation.